model = dict(
    type='AVSegFormerUFE',
    neck=None,
    backbone=dict(
        type='res50',
        init_weights_path='/avsbench/pretrained_backbones/resnet50-19c8e357.pth'),
    vggish=dict(
        freeze_audio_extractor=True,
        pretrained_vggish_model_path='/avsbench/pretrained_backbones/vggish-10086976.pth',
        preprocess_audio_to_log_mel=False,
        postprocess_log_mel_with_pca=False,
        pretrained_pca_params_path=None),
    head=dict(
        type='AVSegHeadUFE',
        in_channels=[256, 512, 1024, 2048],
        num_classes=1,
        query_num=300,
        use_learnable_queries=True,
        fusion_block=dict(type='CrossModalMixer'),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128),
        query_generator=dict(
            type='AttentionGenerator',
            num_layers=6,
            query_num=300),
        transformer=dict(
            type='AVSTransformer',
            encoder=dict(
                num_layers=6,
                layer=dict(
                    dim=256,
                    ffn_dim=2048,
                    dropout=0.1)),
            decoder=dict(
                num_layers=6,
                layer=dict(
                    dim=256,
                    ffn_dim=2048,
                    dropout=0.1)))),
    audio_dim=128,
    embed_dim=256,
    freeze_audio_backbone=True,
    T=5)
dataset = dict(
    train_label=dict(
        type='S4DatasetUFE',
        split='train',
        label=True,
        anno_csv='/avsbench/Single-source/s4_meta_data.csv',
        anno_csv_semi="/avsbench/Single-source/s4_semi_meta_data.csv",
        dir_img='/avsbench/Single-source/s4_data/visual_frames',
        dir_audio_log_mel='/avsbench/Single-source/s4_data/audio_log_mel',
        dir_mask='/avsbench/Single-source/s4_data/gt_masks',
        dir_flow_x="/avsbench/Single-source/s4_data/S4_flows/flows_x",
        dir_flow_y="/avsbench/Single-source/s4_data/S4_flows/flows_y",
        img_size=(224, 224),
        batch_size=16),
    train_unlabel=dict(
        type='S4DatasetUFE',
        split='train',
        label=False,
        anno_csv='/avsbench/Single-source/s4_meta_data.csv',
        anno_csv_semi="/avsbench/Single-source/s4_semi_meta_data.csv",
        dir_img='/avsbench/Single-source/s4_data/visual_frames',
        dir_audio_log_mel='/avsbench/Single-source/s4_data/audio_log_mel',
        dir_mask='/avsbench/Single-source/s4_data/gt_masks',
        dir_flow_x="/avsbench/Single-source/s4_data/S4_flows/flows_x",
        dir_flow_y="/avsbench/Single-source/s4_data/S4_flows/flows_y",
        img_size=(224, 224),
        batch_size=16),
    val=dict(
        type='S4DatasetUFE',
        split='val',
        anno_csv='/avsbench/Single-source/s4_meta_data.csv',
        anno_csv_semi="/avsbench/Single-source/s4_semi_meta_data.csv",
        dir_img='/avsbench/Single-source/s4_data/visual_frames',
        dir_audio_log_mel='/avsbench/Single-source/s4_data/audio_log_mel',
        dir_mask='/avsbench/Single-source/s4_data/gt_masks',
        dir_flow_x="/avsbench/Single-source/s4_data/S4_flows/flows_x",
        dir_flow_y="/avsbench/Single-source/s4_data/S4_flows/flows_y",
        img_size=(224, 224),
        batch_size=16),
    test=dict(
        type='S4DatasetUFE',
        split='test',
        anno_csv='/avsbench/Single-source/s4_meta_data.csv',
        anno_csv_semi="/avsbench/Single-source/s4_semi_meta_data.csv",
        dir_img='/avsbench/Single-source/s4_data/visual_frames',
        dir_audio_log_mel='/avsbench/Single-source/s4_data/audio_log_mel',
        dir_mask='/avsbench/Single-source/s4_data/gt_masks',
        dir_flow_x="/avsbench/Single-source/s4_data/S4_flows/flows_x",
        dir_flow_y="/avsbench/Single-source/s4_data/S4_flows/flows_y",
        img_size=(224, 224),
        batch_size=16))
optimizer = dict(
    type='AdamW',
    lr=2e-5)
loss = dict(
    weight_dict=dict(
        iou_loss=1.0,
        mix_loss=0.1),
    loss_type='dice')
process = dict(
    num_works=8,
    train_epochs=200,
    freeze_epochs=5)
